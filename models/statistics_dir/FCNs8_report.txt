+--------------------+-----------------+----------------+-----------+-------------------+-----------------+-----------------+----------+
|       FCNs8        |    layer name   | Neuron numbers |  MACs (M) |     Parameters    |   Input shape   |   Output shape  |  Kernel  |
+--------------------+-----------------+----------------+-----------+-------------------+-----------------+-----------------+----------+
|      input_1       |    InputLayer   |       -        |     -     |         -         |        -        |        -        |    -     |
|    block1_conv1    |      Conv2D     |   3211264.0    |    86.7   |        1792       |  (224, 224, 3)  |  (224, 224, 64) |  (3, 3)  |
|    block1_conv2    |      Conv2D     |   3211264.0    |  1849.69  |       36928       |  (224, 224, 64) |  (224, 224, 64) |  (3, 3)  |
|    block1_pool     |   MaxPooling2D  |     802816     |    2.41   |         0         |  (224, 224, 64) |  (112, 112, 64) |   2.0    |
|    block2_conv1    |      Conv2D     |   1605632.0    |   924.84  |       73856       |  (112, 112, 64) | (112, 112, 128) |  (3, 3)  |
|    block2_conv2    |      Conv2D     |   1605632.0    |  1849.69  |       147584      | (112, 112, 128) | (112, 112, 128) |  (3, 3)  |
|    block2_pool     |   MaxPooling2D  |     401408     |    1.2    |         0         | (112, 112, 128) |  (56, 56, 128)  |   2.0    |
|    block3_conv1    |      Conv2D     |    802816.0    |   924.84  |       295168      |  (56, 56, 128)  |  (56, 56, 256)  |  (3, 3)  |
|    block3_conv2    |      Conv2D     |    802816.0    |  1849.69  |       590080      |  (56, 56, 256)  |  (56, 56, 256)  |  (3, 3)  |
|    block3_conv3    |      Conv2D     |    802816.0    |  1849.69  |       590080      |  (56, 56, 256)  |  (56, 56, 256)  |  (3, 3)  |
|    block3_pool     |   MaxPooling2D  |     200704     |    0.6    |         0         |  (56, 56, 256)  |  (28, 28, 256)  |   2.0    |
|    block4_conv1    |      Conv2D     |    401408.0    |   924.84  |      1180160      |  (28, 28, 256)  |  (28, 28, 512)  |  (3, 3)  |
|    block4_conv2    |      Conv2D     |    401408.0    |  1849.69  |      2359808      |  (28, 28, 512)  |  (28, 28, 512)  |  (3, 3)  |
|    block4_conv3    |      Conv2D     |    401408.0    |  1849.69  |      2359808      |  (28, 28, 512)  |  (28, 28, 512)  |  (3, 3)  |
|    block4_pool     |   MaxPooling2D  |     100352     |    0.3    |         0         |  (28, 28, 512)  |  (14, 14, 512)  |   2.0    |
|    block5_conv1    |      Conv2D     |    100352.0    |   462.42  |      2359808      |  (14, 14, 512)  |  (14, 14, 512)  |  (3, 3)  |
|    block5_conv2    |      Conv2D     |    100352.0    |   462.42  |      2359808      |  (14, 14, 512)  |  (14, 14, 512)  |  (3, 3)  |
|    block5_conv3    |      Conv2D     |    100352.0    |   462.42  |      2359808      |  (14, 14, 512)  |  (14, 14, 512)  |  (3, 3)  |
|    block5_pool     |   MaxPooling2D  |     25088      |    0.08   |         0         |  (14, 14, 512)  |   (7, 7, 512)   |   2.0    |
|  block6_conv2d_1   |      Conv2D     |    200704.0    |  5035.26  |     102764544     |   (7, 7, 512)   |   (7, 7, 4096)  |  (7, 7)  |
|  block6_conv2d_2   |      Conv2D     |    200704.0    |   822.08  |      16781312     |   (7, 7, 4096)  |   (7, 7, 4096)  |  (1, 1)  |
|  block7_conv2d_1   |      Conv2D     |     980.0      |    4.01   |       81940       |   (7, 7, 4096)  |    (7, 7, 20)   |  (1, 1)  |
|  block8_conv2d_1   |      Conv2D     |     3920.0     |    2.01   |       10260       |  (14, 14, 512)  |   (14, 14, 20)  |  (1, 1)  |
|  conv2d_transpose  | Conv2DTranspose |     3920.0     |    0.31   |        6400       |    (7, 7, 20)   |   (14, 14, 20)  |  (4, 4)  |
|  block8_conv2d_2   |      Conv2D     |    15680.0     |    4.01   |        5140       |  (28, 28, 256)  |   (28, 28, 20)  |  (1, 1)  |
| conv2d_transpose_1 | Conv2DTranspose |    15680.0     |    1.25   |        6400       |   (14, 14, 20)  |   (28, 28, 20)  |  (4, 4)  |
| conv2d_transpose_2 | Conv2DTranspose |   1003520.0    |   80.28   |       102400      |   (28, 28, 20)  |  (224, 224, 20) | (16, 16) |
|       Total        |        -        |    15.14 M     | 21.2959 G | 134.473/134.473 M |        -        |        -        |    -     |
+--------------------+-----------------+----------------+-----------+-------------------+-----------------+-----------------+----------+

2 * MACs = FLOPs